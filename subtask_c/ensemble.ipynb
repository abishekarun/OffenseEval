{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Riv1NfxbnfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_table(\"offenseval-training-v1.tsv\",sep='\\t',index_col=False, error_bad_lines=False) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7ntT8V6fVcj",
        "colab_type": "code",
        "outputId": "7dbfd3b9-7130-4ad3-b030-a8605cb6e706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X_test.subtask_c.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IND    482\n",
              "GRP    215\n",
              "OTH     79\n",
              "Name: subtask_c, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrLQKMHwMx-2",
        "colab_type": "text"
      },
      "source": [
        "### Machine Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBmBSkHGM3HG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from scipy.stats import itemfreq\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,HashingVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "porter_stemmer = PorterStemmer()  \n",
        "  \n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV_G649SM3PL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatize_sentences(sentence):\n",
        "    tokens = sentence.split()\n",
        "    lm_tokens = [wordnet_lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(lm_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3SJcO5qM3MZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(content):\n",
        "  content=content.str.lower()                                                         # Convert to Lowercase\n",
        "  content=content.str.replace('@USER','')                                     # Remove triggerword tags\n",
        "  content=content.str.replace('username','')                                          # Remove username tags\n",
        "  content=content.str.replace('http\\S+|www.\\S+', '')                                  # Remove Links\n",
        "  content=content.str.replace('\\s+', ' ')                                             # Remove multiple spaces\n",
        "  content=content.str.replace('[^A-Za-z\\s]+', '')                                     # Remove irrelevant characters other than alphabets and space\n",
        "  #content=content.apply(lemmatize_sentences)\n",
        "  return content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8QyVRoAM3Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['tweet'] = clean_text(df['tweet'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxxx05JXBTxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.loc[df['subtask_a'] == 'OFF']\n",
        "df = df.loc[df['subtask_b'] == 'TIN']\n",
        "df = df.drop(['subtask_a','subtask_b'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of62SRioBz5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "taskc_data = df[['tweet','subtask_c']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZBT_fnS_wx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test = train_test_split(taskc_data, test_size=0.2, random_state=0, stratify=taskc_data['subtask_c'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg7Gzg0uigSV",
        "colab_type": "code",
        "outputId": "cb1a435c-ede1-4b3b-924e-59dc0c12125e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3100, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A58AUX-pd1dG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.to_csv('original_train.tsv',sep='\\t',index=False)\n",
        "X_test.to_csv('original_dev.tsv',sep='\\t',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai4C-R-NNOZp",
        "colab_type": "code",
        "outputId": "ea644de2-797a-4024-e6f0-26af4c1c0594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_train = pd.read_csv('original_train.tsv',sep='\\t')\n",
        "X_test = pd.read_csv('original_dev.tsv',sep='\\t')\n",
        "\n",
        "le1=LabelEncoder()\n",
        "X_train.subtask_c=le1.fit_transform(X_train.subtask_c)\n",
        "X_test.subtask_c=le1.transform(X_test.subtask_c)\n",
        "\n",
        "tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1,2))\n",
        "model1 = LogisticRegression(solver='lbfgs')\n",
        "model2 = AdaBoostClassifier()\n",
        "model3 = XGBClassifier()\n",
        "# create the ensemble model\n",
        "eclf1 = VotingClassifier(estimators=[('LogReg', model1), ('adaboost', model2), ('xgboost', model3)], voting='soft')\n",
        "\n",
        "ROS_pipeline = make_pipeline(tvec, RandomOverSampler(random_state=777),eclf1)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "lr_fit = ROS_pipeline.fit(X_train.tweet, X_train.subtask_c)\n",
        "model1_probs = lr_fit.predict_proba(X_test.tweet)"
      ],
      "execution_count": 0,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "759cd34e-5f3e-4145-e7eb-2582f3897fb2",
        "id": "1UKMUlshkbeT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Print f1 score and confusion matrix of best model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.56822 \n",
            "[[135  48  32]\n",
            " [ 68 393  21]\n",
            " [ 28  30  21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbryViAgOI9s",
        "colab_type": "text"
      },
      "source": [
        "# Second model (All classes equal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCUHgwleOIPM",
        "colab_type": "code",
        "outputId": "816a0a61-1ceb-4ef5-b7b1-0a5a76ee8fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_train = pd.read_csv('all_train_data.tsv',sep='\\t') \n",
        "X_test = pd.read_csv('all_dev_data.tsv',sep='\\t') \n",
        "le1=LabelEncoder()\n",
        "X_train.subtask_c=le1.fit_transform(X_train.subtask_c)\n",
        "X_test.subtask_c=le1.transform(X_test.subtask_c)\n",
        "tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1, 2))\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "NM2_pipeline = make_pipeline(tvec, NearMiss(ratio='not minority',random_state=777, version = 2),model)\n",
        "lr_fit = NM2_pipeline.fit(X_train.tweet, X_train.subtask_c)\n",
        "model2_probs = lr_fit.predict_proba(X_test.tweet)"
      ],
      "execution_count": 0,
      "outputs": [
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBKFCyYmN7oB",
        "colab_type": "text"
      },
      "source": [
        "# Third model (Make OTH classes equal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIMsotxcOkle",
        "colab_type": "code",
        "outputId": "56c60c0c-823a-4eb9-fd4a-338eb8e1c0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_train = pd.read_csv('oth_train_data.tsv',sep='\\t') \n",
        "X_test = pd.read_csv('oth_dev_data.tsv',sep='\\t') \n",
        "le1=LabelEncoder()\n",
        "X_train.subtask_c=le1.fit_transform(X_train.subtask_c)\n",
        "X_test.subtask_c=le1.transform(X_test.subtask_c)\n",
        "lr_fit = ROS_pipeline.fit(X_train.tweet, X_train.subtask_c)\n",
        "model3_probs = lr_fit.predict_proba(X_test.tweet)"
      ],
      "execution_count": 0,
      "outputs": [
        
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abNVqvLDPGUL",
        "colab_type": "text"
      },
      "source": [
        "# Fourth model (Make grp classes equal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5HDScnxPaCs",
        "colab_type": "code",
        "outputId": "55372296-f4b5-4f2f-fa84-bc9b0ecca694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_train = pd.read_csv('grp_train_data.tsv',sep='\\t') \n",
        "X_test = pd.read_csv('grp_dev_data.tsv',sep='\\t') \n",
        "le1=LabelEncoder()\n",
        "X_train.subtask_c=le1.fit_transform(X_train.subtask_c)\n",
        "X_test.subtask_c=le1.transform(X_test.subtask_c)\n",
        "tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1,2))\n",
        "model1 = LogisticRegression(solver='lbfgs')\n",
        "model2 = AdaBoostClassifier()\n",
        "model3 = XGBClassifier()\n",
        "# create the ensemble model\n",
        "eclf1 = VotingClassifier(estimators=[('LogReg', model1), ('adaboost', model2), ('xgboost', model3)], voting='soft')\n",
        "\n",
        "ROS_pipeline = make_pipeline(tvec, RandomOverSampler(random_state=777),eclf1)\n",
        "lr_fit = ROS_pipeline.fit(X_train.tweet, X_train.subtask_c)\n",
        "model4_probs = lr_fit.predict_proba(X_test.tweet)"
      ],
      "execution_count": 0,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIa0zWPzU8Kk",
        "colab_type": "code",
        "outputId": "1d7d6b88-62d2-4bcb-c2b0-c3a41a0346a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = (model2_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.54319 \n",
            "[[124  51  40]\n",
            " [ 71 384  27]\n",
            " [ 26  32  21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujTF1ZY5U8SZ",
        "colab_type": "code",
        "outputId": "19cfb0f2-62f6-4d68-86e0-974a6c366cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = (model3_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.54665 \n",
            "[[119  38  58]\n",
            " [ 63 365  54]\n",
            " [ 22  27  30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1AGMKuYU8aM",
        "colab_type": "code",
        "outputId": "09280ae5-d387-4912-de0d-96e38bca42fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = (model4_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.56126 \n",
            "[[141  44  30]\n",
            " [ 95 373  14]\n",
            " [ 27  31  21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfOV9ZJSSNa2",
        "colab_type": "code",
        "outputId": "643b1293-a696-4f21-bba3-c6f8bee3abfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = 0.5*(model1_probs + model2_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.54792 \n",
            "[[129  50  36]\n",
            " [ 69 390  23]\n",
            " [ 30  30  19]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln7ruT1rSNdz",
        "colab_type": "code",
        "outputId": "0b22303c-f04f-4475-d1c0-b9388f3097fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = 0.5*(model1_probs + model3_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.55235 \n",
            "[[129  45  41]\n",
            " [ 62 383  37]\n",
            " [ 26  31  22]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cQH_mhvUDzD",
        "colab_type": "code",
        "outputId": "846acdc1-bb1e-4870-f366-218641617e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = 0.5*(model1_probs + model4_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.57605 \n",
            "[[142  45  28]\n",
            " [ 80 388  14]\n",
            " [ 27  31  21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEBfTZnMUEJW",
        "colab_type": "code",
        "outputId": "2d8b5e49-bdb6-491f-a937-8f42f12c2bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = 0.5*(model2_probs + model3_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.54660 \n",
            "[[125  48  42]\n",
            " [ 68 379  35]\n",
            " [ 27  29  23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRbFmVyLUERK",
        "colab_type": "code",
        "outputId": "931a6094-fc86-45bc-fb92-617121fac4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = 0.5*(model2_probs + model4_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.54629 \n",
            "[[137  47  31]\n",
            " [ 79 379  24]\n",
            " [ 29  32  18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5buh32TtUEZ1",
        "colab_type": "code",
        "outputId": "0e8a389c-4dd0-4597-e40a-18df4d2ff31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = 0.5*(model3_probs + model4_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.55645 \n",
            "[[135  43  37]\n",
            " [ 77 373  32]\n",
            " [ 25  31  23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6oddA5yUEg3",
        "colab_type": "code",
        "outputId": "deea039d-7041-4a68-bbbf-920c043fddc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = (model1_probs + model2_probs+model3_probs)/3\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.55762 \n",
            "[[131  45  39]\n",
            " [ 69 381  32]\n",
            " [ 25  31  23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhijWRsWUOt6",
        "colab_type": "code",
        "outputId": "aef0739c-8cba-4566-d5c2-f1bfa7fc7bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = (model1_probs + model2_probs+model4_probs)/3\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.56236 \n",
            "[[140  44  31]\n",
            " [ 74 388  20]\n",
            " [ 30  30  19]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOCdpoc6UO1I",
        "colab_type": "code",
        "outputId": "c53ab6ee-5770-4010-e2f9-e129cf595de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = (model1_probs + model4_probs+model3_probs)/3\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.57492 \n",
            "[[139  42  34]\n",
            " [ 73 386  23]\n",
            " [ 25  31  23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zne09dkpUO_e",
        "colab_type": "code",
        "outputId": "9d9efa92-bf76-45de-c656-ff53c9139186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = (model4_probs + model2_probs+model3_probs)/3\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.54986 \n",
            "[[135  42  38]\n",
            " [ 75 379  28]\n",
            " [ 29  30  20]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0H-b6x9UPLt",
        "colab_type": "code",
        "outputId": "52ee4d9b-df80-4049-c712-7e0de66051cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "final_prob = 0.25*(model1_probs + model2_probs+model3_probs+model4_probs)\n",
        "final_preds = np.argmax(final_prob,axis=1)\n",
        "f1=f1_score(X_test.subtask_c, final_preds, average='macro')\n",
        "print(\"f1 score: {:.5f} \".format(f1))\n",
        "print(confusion_matrix(X_test.subtask_c, final_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score: 0.55876 \n",
            "[[135  44  36]\n",
            " [ 72 384  26]\n",
            " [ 28  30  21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0gW3o3_beFL",
        "colab_type": "text"
      },
      "source": [
        "# Get text predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vnyssGfbdCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('test_set_taskc.tsv',sep='\\t')\n",
        "test.tweet = clean_text(test.tweet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8q3t2MOep6n",
        "colab_type": "code",
        "outputId": "89165bbb-1ba5-4c39-98ec-ee4d3d34b426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_train = pd.read_csv('original_train.tsv',sep='\\t')\n",
        "X_test = pd.read_csv('original_dev.tsv',sep='\\t')\n",
        "X_train = X_train.append(X_test)\n",
        "le1=LabelEncoder()\n",
        "X_train.subtask_c=le1.fit_transform(X_train.subtask_c)\n",
        "X_test.subtask_c=le1.transform(X_test.subtask_c)\n",
        "tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1,2))\n",
        "model1 = LogisticRegression(solver='lbfgs')\n",
        "model2 = AdaBoostClassifier()\n",
        "model3 = XGBClassifier()\n",
        "# create the ensemble model\n",
        "eclf1 = VotingClassifier(estimators=[('LogReg', model1), ('adaboost', model2), ('xgboost', model3)], voting='soft')\n",
        "\n",
        "ROS_pipeline = make_pipeline(tvec, RandomOverSampler(random_state=777),eclf1)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "lr_fit = ROS_pipeline.fit(X_train.tweet, X_train.subtask_c)\n",
        "model1_probs = lr_fit.predict_proba(test.tweet)"
      ],
      "execution_count": 0,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKu3c4hfpnYp",
        "colab_type": "code",
        "outputId": "fd4a3043-3272-4d69-979a-69a130557bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_train = pd.read_csv('oth_train_data.tsv',sep='\\t') \n",
        "X_test = pd.read_csv('oth_dev_data.tsv',sep='\\t') \n",
        "X_train = X_train.append(X_test)\n",
        "le1=LabelEncoder()\n",
        "X_train.subtask_c=le1.fit_transform(X_train.subtask_c)\n",
        "X_test.subtask_c=le1.transform(X_test.subtask_c)\n",
        "lr_fit = ROS_pipeline.fit(X_train.tweet, X_train.subtask_c)\n",
        "model3_probs = lr_fit.predict_proba(test.tweet)"
      ],
      "execution_count": 0,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwnuQ9ZIeqlm",
        "colab_type": "code",
        "outputId": "e3881132-6ad9-4275-f4bc-4924c4cdf3b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_train = pd.read_csv('grp_train_data.tsv',sep='\\t') \n",
        "X_test = pd.read_csv('grp_dev_data.tsv',sep='\\t') \n",
        "X_train = X_train.append(X_test)\n",
        "le1=LabelEncoder()\n",
        "X_train.subtask_c=le1.fit_transform(X_train.subtask_c)\n",
        "X_test.subtask_c=le1.transform(X_test.subtask_c)\n",
        "tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1,2))\n",
        "model1 = LogisticRegression(solver='lbfgs')\n",
        "model2 = AdaBoostClassifier()\n",
        "model3 = XGBClassifier()\n",
        "# create the ensemble model\n",
        "eclf1 = VotingClassifier(estimators=[('LogReg', model1), ('adaboost', model2), ('xgboost', model3)], voting='soft')\n",
        "\n",
        "ROS_pipeline = make_pipeline(tvec, RandomOverSampler(random_state=777),eclf1)\n",
        "lr_fit = ROS_pipeline.fit(X_train.tweet, X_train.subtask_c)\n",
        "model4_probs = lr_fit.predict_proba(test.tweet)"
      ],
      "execution_count": 0,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUw6_w4Me3g0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''   \n",
        "final_pred=[0]*len(first_pred)\n",
        "for i in range(len(first_pred)):\n",
        "  if(first_pred[i] == 0):\n",
        "    final_pred[i]='GRP'\n",
        "  elif(second_pred[i] == 1):\n",
        "    final_pred[i]='IND'\n",
        "  else:\n",
        "    final_pred[i]='OTH'\n",
        "    \n",
        "'''\n",
        "final_prob = (model1_probs + model4_probs+model3_probs)/3\n",
        "prediction = np.argmax(final_prob,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4YYz06Ce_uQ",
        "colab_type": "code",
        "outputId": "cc3226f4-5fd7-4a14-82a1-f5c7439786d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "unique, counts = np.unique(prediction, return_counts=True)\n",
        "\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0  94]\n",
            " [  1 105]\n",
            " [  2  14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKO2myzTmdTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = np.where(prediction == 0, 'GRP', \n",
        "                      np.where(prediction == 1, 'IND', 'OTH'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQmUTteGfJaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = pd.DataFrame({'id':test.id, 'subtask_b':prediction})\n",
        "results.to_csv('submission3.csv',sep=',',header=False,index=False)\n",
        "files.download('submission3.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}